{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n","<hr>\n","\n","# Introduction\n","\n","This notebook demonstrates how to use a 1-dimensional convolutional neural network to detect technical trading patterns. In particular, this example trains the model to detect the head and shoulders pattern.\n","\n","# Generate Chart Patterns\n","\n","The following code block generates 100,000 samples of the head and shoulders pattern. Each sample consists of 25 data points but each sample contains some randomness to make it unique.\n","\n","<img src=\"https://cdn.quantconnect.com/i/tu/head-and-shoulders-pattern-1.png\" alt=\"Head and shoulders pattern\" style=\"width: 800px; max-width: 100%;\">\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from scipy.stats import norm, uniform\n","\n","np.random.seed(1)\n","ref_count = 100_000\n","v1 = np.array([0] * ref_count) + 0.02 * norm.rvs(size=(ref_count,))\n","p1 = np.array([1] * ref_count) + 0.2 * norm.rvs(size=(ref_count,))\n","v2 = v1 + 0.2 * norm.rvs(size=(ref_count,))\n","v3 = v1 + 0.2 * norm.rvs(size=(ref_count,))\n","p3 = p1 + 0.02 * norm.rvs(size=(ref_count,))\n","p2 = 1.5 * np.maximum(p1, p3) + abs(uniform.rvs(size=(ref_count,)))\n","v4 = v1 + 0.02 * norm.rvs(size=(ref_count,))\n","ref = pd.DataFrame([\n","    v1, \n","    (v1*.75 + p1*.25) + 0.2 * norm.rvs(size=(ref_count,)), \n","    (v1+p1)/2 + 0.2 * norm.rvs(size=(ref_count,)), \n","    (v1*.25 + p1*.75) + 0.2 * norm.rvs(size=(ref_count,)), \n","    p1, \n","    (v2*.25 + p1*.75) + 0.2 * norm.rvs(size=(ref_count,)), \n","    (v2+p1)/2 + 0.2 * norm.rvs(size=(ref_count,)), \n","    (v2*.75 + p1*.25) + 0.2 * norm.rvs(size=(ref_count,)), \n","    v2, \n","    (v2*.75 + p2*.25) + 0.2 * norm.rvs(size=(ref_count,)), \n","    (v2+p2)/2 + 0.2 * norm.rvs(size=(ref_count,)), \n","    (v2*.25 + p2*.75) + 0.2 * norm.rvs(size=(ref_count,)), \n","    p2, \n","    (v3*.25 + p2*.75) + 0.2 * norm.rvs(size=(ref_count,)), \n","    (v3+p2)/2 + 0.2 * norm.rvs(size=(ref_count,)), \n","    (v3*.75 + p2*.25) + 0.2 * norm.rvs(size=(ref_count,)), \n","    v3, \n","    (v3*.75 + p3*.25) + 0.2 * norm.rvs(size=(ref_count,)), \n","    (v3+p3)/2 + 0.2 * norm.rvs(size=(ref_count,)), \n","    (v3*.25 + p3*.75) + 0.2 * norm.rvs(size=(ref_count,)), \n","    p3, \n","    (v4*.25 + p3*.75) + 0.2 * norm.rvs(size=(ref_count,)), \n","    (v4+p3)/2 + 0.2 * norm.rvs(size=(ref_count,)), \n","    (v4*.75 + p3*.25) + 0.2 * norm.rvs(size=(ref_count,)), \n","    v4\n","])\n","\n","ref = ((ref - ref.mean()) / ref.std()).T\n","display(ref)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Create Training Data\n","The positive training samples are the samples we created above."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import plotly.graph_objects as go\n","\n","# Generate positive samples.\n","positive_samples = []\n","for _, row in ref.iterrows():    \n","    positive_samples.append(row.values)\n","# Show one of the positive samples.\n","fig = go.Figure(go.Scatter(x=ref.columns, y=positive_samples[0], mode='lines'))\n","fig.update_layout(\n","    title='Positive Sample<br><sup>Example head and shoulders pattern'\n","        + ' to train the model</sup>', \n","    xaxis_title='Data Point', yaxis_title='Value', width=500, height=500\n",")\n","fig.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The negative training samples are random walks."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Generate negative samples.\n","equity_curves = (\n","    np.random.randn(ref.shape[0], ref.shape[1]) / 1000 + 1\n",").cumprod(axis=1)\n","negative_samples = (\n","    (equity_curves - np.mean(equity_curves, axis=1, keepdims=True))\n","    / np.std(equity_curves, axis=1, keepdims=True)\n",")\n","# Show one of the negative samples.\n","fig = go.Figure(go.Scatter(x=ref.columns, y=negative_samples[0], mode='lines'))\n","fig.update_layout(\n","    title='Negative Sample<br><sup>Example of the absense of the pattern'\n","        + ' to train the model</sup>', \n","    xaxis_title='Data Point', yaxis_title='Value', width=500, height=500\n",")\n","fig.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["To ensure our model has a balanced training dataset, let's alternate between positive and negative samples."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Create samples of features and labels.\n","X = np.array(\n","    [\n","        value \n","        for pair in zip(positive_samples, negative_samples) \n","        for value in pair\n","    ]\n",")\n","y = np.array([1 if i % 2 == 0 else 0 for i in range(len(X))])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Build & Train the CNN Model\n","\n","With the data samples created, you can now split it into training and testing datasets, train the neural network, and then run an out-of-sample test."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Input\n","from keras.utils import set_random_seed\n","\n","set_random_seed(0)\n","\n","# Split the data into training and testing sets.\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, shuffle=False\n",")\n","\n","X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n","X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n","\n","# Build the CNN model.\n","model = Sequential()\n","model.add(Input(shape=(X_train.shape[1], 1)))\n","model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model.\n","model.compile(\n","    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']\n",")\n","\n","# Train the model.\n","model.fit(\n","    X_train, y_train, epochs=10, batch_size=16, \n","    validation_data=(X_test, y_test)\n",")\n","\n","# Generate and plot the OOS predictions.\n","predictions = model.predict(X_test)\n","go.Figure(\n","    go.Scatter(\n","        x=list(range(100)), y=predictions[:100, :].flatten(), name='Prediction'\n","    ),\n","    dict(\n","        title='Predictions<br><sup>Alternative between positive and negatve '\n","            + 'samples makes the plot jump between 0 and 1</sup>', \n","        xaxis_title='Sample Number', \n","        yaxis_title='Probability of Pattern', showlegend=True\n","    )\n",").show()\n","\n","# Evaluate the model.\n","test_loss, test_acc = model.evaluate(X_test, y_test)\n","print(f'Test Accuracy: {test_acc}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Use the CNN to Identify H&S Patterns in Real Forex Prices\n","\n","At this point, you've trained the model using fake data. Let's see how well the model can detect the head and shoulders pattern in real Forex data. In this example, use the daily USDCAD exchange rate."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["qb = QuantBook()\n","symbol = qb.add_forex(\"USDCAD\").symbol\n","prices = qb.history(\n","    symbol, datetime(2012, 1, 1), datetime(2024, 1, 1), Resolution.DAILY\n",").loc[symbol]['close']"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["All the head and shoulders patterns we created in the first cell of this notebook consisted of 25 data points, but the head and shoulders pattern can present itself over a longer period of time. To detect the pattern over longer periods of time, let's define a method that transforms any number of data points >25 down to 25 data points while retaining the general shape of the original data points."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def downsample(values, num_points=25):\n","    if num_points == len(values):\n","        return values\n","\n","    adj_values = []\n","    duplicates = int(2 * len(values) / num_points)\n","    if duplicates > 0:\n","        for x in values:\n","            for i in range(duplicates):\n","                adj_values.append(x)\n","    else:\n","        adj_values = values\n","    \n","    num_steps = num_points - 2\n","    step_size = int(len(adj_values) / num_steps)\n","\n","    smoothed_data = [adj_values[0]]\n","    for i in range(num_steps):\n","        start_idx = i * step_size\n","        if i == num_steps - 1:\n","            end_idx = len(adj_values) - 1\n","        else:\n","            end_idx = (i + 1) * step_size - 1\n","        segment = np.array(adj_values[start_idx : end_idx+1])\n","\n","        avg = sum(segment) / len(segment)\n","        smoothed_data.append(avg)\n","        \n","    smoothed_data.append(adj_values[-1])\n","\n","    return np.array(smoothed_data)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Now let's scan through the USDCAD closing prices and search for the head and shoulders pattern. When the model is at least 80% confident it found the pattern, the following code block displays the price path."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from plotly.subplots import make_subplots\n","\n","min_size = ref.shape[1]\n","max_size = 100\n","step_size = 10\n","confidence_threshold = 0.8  # 0.8 => 80%\n","\n","for i in prices.index:\n","    # Get the trailing prices for this timestep.\n","    trailing_prices = prices.loc[:i]\n","\n","    for size in range(min_size, max_size+1, step_size):\n","        # Ensure there are enough trailing data points to fill this \n","        # window size.\n","        if len(trailing_prices) < size:\n","            continue\n","\n","        window_trailing_prices = trailing_prices.iloc[-size:]\n","        # Downsample the trailing prices in this window to be 25 data \n","        # points.\n","        low_res_window = downsample(window_trailing_prices.values)\n","        # Standardize the downsampled trailing prices.\n","        factors = np.array(\n","            (\n","                (low_res_window - low_res_window.mean()) \n","                / low_res_window.std()\n","            ).reshape(1, min_size, 1)\n","        )\n","        # Get the probability of the technical trading pattern in the \n","        # downsampled and standardized window.\n","        prediction = model.predict(factors, verbose=0)[0][0]\n","        if prediction > confidence_threshold:\n","            print(\n","                f\"Pattern detected between \"\n","                + f\"{window_trailing_prices.index[0]} and \"\n","                + f\"{window_trailing_prices.index[-1]} with \"\n","                + f\"{round(prediction * 100, 1)}% confidence:\"\n","            )\n","\n","            fig = make_subplots(\n","                rows=1, cols=2, subplot_titles=[\n","                    \"Price Over Time\", \"Downsampled Price Over Time\"\n","                ]\n","            )\n","            fig.add_trace(\n","                go.Scatter(\n","                    x=window_trailing_prices.index, y=window_trailing_prices, \n","                    mode='lines', name='Price'\n","                ), \n","                row=1, col=1\n","            )\n","            fig.add_trace(\n","                go.Scatter(\n","                    x=list(range(len(low_res_window))), y=low_res_window,\n","                    mode='lines', name='Downsampled Price'\n","                ), \n","                row=1, col=2\n","            )\n","\n","            fig.update_layout(\n","                title='Detected Pattern<br><sup>The raw data sample and the '\n","                    + 'downsampled version of it</sup>',\n","                showlegend=False\n","            )\n","            fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n","            fig.update_xaxes(title_text=\"Data Point\", row=1, col=2)\n","            fig.update_yaxes(title_text=\"Price\", row=1, col=1)\n","            fig.update_yaxes(title_text=\"Price\", row=1, col=2)\n","            fig.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Save the Model\n","\n","Save the model into the Object Store so that you can run a backtest with it in the `main.py` file."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.save(qb.object_store.get_file_path(\"head-and-shoulders-model.keras\"))"]}],"metadata":{"kernelspec":{"display_name":"Foundation-Py-Default","language":"python","name":"python3"},"vscode":{"interpreter":{"hash":"3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"}}},"nbformat":4,"nbformat_minor":2}
