{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a793a7ac",
   "metadata": {},
   "source": [
    "![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n",
    "<hr>\n",
    "\n",
    "# FOREX Strategy using Corrective Artificial Intelligence (CAI)\n",
    "\n",
    "This notebook connects to PredictNow, trains a model, and generates predictions.\n",
    "\n",
    "The model hypothesis is that USD will rise against the EUR during EUR business hours and fall during the USD business hours. This is called the time of the day effect and seen due to HF OF and returns (https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2099321)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be98a3f",
   "metadata": {},
   "source": [
    "### Connect to PredictNow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554e706-aa36-4c15-a113-e9efe9c54686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AlgorithmImports import *\n",
    "from QuantConnect.PredictNowNET import PredictNowClient\n",
    "from QuantConnect.PredictNowNET.Models import *\n",
    "from datetime import datetime, time\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "qb = QuantBook()\n",
    "client = PredictNowClient(\"jared@quantconnect.com\", \"jared_broad\")\n",
    "client.connected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ee3df4-bac0-4b3a-9901-998f91e98e12",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "In this notebook, we will create a strategy that short EURUSD when Europe is open and long when Europe is closed and US is open. We will aggregate the daily return of this static strategy that is activate everyday, and use CAI to predict if the strategy is profitable for a given date. We will follow this On and Off signal to create a dynamic strategy and benchmark its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339af376-5b66-4653-84c0-1c66e25b7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load minute bar data of EURUSD\n",
    "symbol = qb.add_forex(\"EURUSD\").symbol\n",
    "df_price = qb.History(symbol, datetime(2020,1,1), datetime(2021,1,1)).loc[symbol]\n",
    "\n",
    "# resample to hourly returns\n",
    "minute_returns = df_price[\"close\"].pct_change()\n",
    "hourly_returns = (minute_returns + 1).resample('H').prod() - 1\n",
    "df_hourly_returns = hourly_returns.to_frame()\n",
    "df_hourly_returns['time'] = df_hourly_returns.index.time\n",
    "\n",
    "# generate buy and sell signals and get strategy returns\n",
    "# Sell EUR.USD when Europe is open\n",
    "sell_eur = ((df_hourly_returns['time'] > time(3)) & (df_hourly_returns['time'] < time(9)))\n",
    "\n",
    "# Buy EUR.USD when Europe is closed and US is open\n",
    "buy_eur = ((df_hourly_returns['time'] > time(11)) & (df_hourly_returns['time'] < time(15)))\n",
    "\n",
    "# signals as 1 and -1\n",
    "ones = pd.DataFrame(1, index=df_hourly_returns.index, columns=['signals'])\n",
    "minus_ones = pd.DataFrame(-1, index=df_hourly_returns.index, columns=['signals'])\n",
    "signals = minus_ones.where(sell_eur, ones.where(buy_eur, 0))\n",
    "\n",
    "# strategy returns\n",
    "strategy_returns = df_hourly_returns['close'] * signals['signals']\n",
    "strategy_returns = (strategy_returns + 1).resample('D').prod() - 1\n",
    "df_strategy_returns = strategy_returns.to_frame().ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff064d5-c498-4905-8a86-7a3c0b82bdff",
   "metadata": {},
   "source": [
    "### Save the Data\n",
    "We will label the data and save it to disk (ObjectStore) with the model name. This file will be uploaded to PredictNow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063d6ad-8da6-4394-8b4f-99b962c29c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model name and data lable\n",
    "model_name = \"fx-time-of-day\"\n",
    "label =  \"strategy_ret\"\n",
    "\n",
    "# Label the data and save it to the object store\n",
    "df_strategy_returns = df_strategy_returns.rename(columns={df_strategy_returns.columns.to_list()[0]: label})\n",
    "parquet_path = qb.object_store.get_file_path(f'{model_name}.parquet')\n",
    "df_strategy_returns.to_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f46a488-b018-4464-af8b-cad8d8454583",
   "metadata": {},
   "source": [
    "### Create the Model\n",
    "Create the model by sending the parameters to PredictNow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67682fb-4e00-47b7-aab1-4f01e7287480",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = ModelParameters(\n",
    "    mode=Mode.TRAIN, \n",
    "    type=ModelType.CLASSIFICATION, \n",
    "    feature_selection=FeatureSelection.SHAP, \n",
    "    analysis=Analysis.SMALL, \n",
    "    boost=Boost.GBDT, \n",
    "    testsize=42.0,\n",
    "    timeseries=False,\n",
    "    probability_calibration=False,    # True if we want to refine your probability\n",
    "    exploratory_data_analysis=False,  # True if we want to use exploratory data analysis\n",
    "    weights=\"no\")                     # yes, no, custom\n",
    "\n",
    "create_model_result = client.create_model(model_name, model_parameters)\n",
    "str(create_model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c01b02c-a519-4853-952c-c2ffad85a0d4",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "Provide the path to the data, and its label.\n",
    "This task may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e5da3-c3c9-4073-a2af-8fa00c88beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_request_result = client.train(model_name, parquet_path, label)\n",
    "str(train_request_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e99965-f29a-41e2-a220-5551bccbd831",
   "metadata": {},
   "source": [
    "### Get the training result\n",
    "The training results include dataframes with eprformance metrics and predicted probability and labels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f176ff6d-01f6-4fb2-ac3b-f89d80d7c0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_result = client.get_training_result(model_name)\n",
    "str(training_result)\n",
    "\n",
    "# Predicted probability (float between 0 and 1) for validation/training data set\n",
    "# the last column notes the probability that it's a \"1\", i.e. positive return\n",
    "predicted_prob_cv = pd.read_json(StringIO(training_result.predicted_prob_cv))\n",
    "print(\"predicted_prob_cv\")\n",
    "print(predicted_prob_cv)\n",
    "\n",
    "# Predicted probability (float between 0 and 1) for the testing data set\n",
    "predicted_prob_test = pd.read_json(StringIO(training_result.predicted_prob_test))\n",
    "print(\"predicted_prob_test\")\n",
    "print(predicted_prob_test)\n",
    "\n",
    "# Predicted label, 0 or 1, for validation/training data set. Classified as class 1 if probability > 0.5\n",
    "predicted_targets_cv = pd.read_json(StringIO(training_result.predicted_targets_cv))\n",
    "print(\"predicted_targets_cv\")\n",
    "print(predicted_targets_cv)\n",
    "\n",
    "# Predicted label, 0 or 1, for testing data set. Classified as class 1 if probability > 0.5\n",
    "predicted_targets_test = pd.read_json(StringIO(training_result.predicted_targets_test))\n",
    "print(\"predicted_targets_test\")\n",
    "print(predicted_targets_test)\n",
    "\n",
    "# Feature importance score, shows what features are being used in the prediction\n",
    "# More helpful when you include your features\n",
    "# and only works when you set feature_selection to FeatureSelection.SHAP or FeatureSelection.CMDA\n",
    "if training_result.feature_importance:\n",
    "    feature_importance = pd.read_json(StringIO(training_result.feature_importance))\n",
    "    print(\"feature_importance\")\n",
    "    print(feature_importance)\n",
    "\n",
    "# Performance metrics in terms of accuracies\n",
    "performance_metrics = pd.read_json(StringIO(training_result.performance_metrics))\n",
    "print(\"performance_metrics\")\n",
    "print(performance_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9680e12-7f14-46e4-b11c-c5d1bce0aa02",
   "metadata": {},
   "source": [
    "### Start Predicting with the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12cc116-2363-4333-a134-119a4e8810de",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result = client.predict(model_name, parquet_path, exploratory_data_analysis=False, probability_calibration=False)\n",
    "str(predict_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Foundation-Py-Default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
